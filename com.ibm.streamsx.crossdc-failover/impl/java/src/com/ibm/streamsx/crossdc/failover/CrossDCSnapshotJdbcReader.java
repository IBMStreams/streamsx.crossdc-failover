/*
===================================================
# Licensed Materials - Property of IBM
# Copyright IBM Corp. 2018, 2019
# US Government Users Restricted Rights - Use, duplication or
# disclosure restricted by GSA ADP Schedule Contract with
# IBM Corp.
===================================================
*/
/* Generated by Streams Studio: April 30, 2019 at 8:40:26 PM EDT */
/*
===================================================
First created on: Apr/30/2019
Last modified on: May/16/2019

This custom Java operator allows us to read a single row  
containing a data snapshot blob for a given primary key or read all rows.
This operator is meant to be used by the crossdc-failover toolkit.

This operator expects a database table with the following schema.
id varchar(256) NOT NULL, replicationTime varchar(256), snapshot BLOB(32M), PRIMARY KEY (id)
===================================================
*/
package com.ibm.streamsx.crossdc.failover;

import java.util.logging.Logger;
import java.io.File;
import java.net.MalformedURLException;

import com.ibm.streams.operator.AbstractOperator;
import com.ibm.streams.operator.OperatorContext;
import com.ibm.streams.operator.OutputTuple;
import com.ibm.streams.operator.StreamingData.Punctuation;
import com.ibm.streams.operator.StreamingInput;
import com.ibm.streams.operator.StreamingOutput;
import com.ibm.streams.operator.Tuple;
import com.ibm.streams.operator.model.InputPortSet;
import com.ibm.streams.operator.model.InputPortSet.WindowMode;
import com.ibm.streams.operator.model.InputPortSet.WindowPunctuationInputMode;
import com.ibm.streams.operator.model.InputPorts;
import com.ibm.streams.operator.model.OutputPortSet;
import com.ibm.streams.operator.model.OutputPortSet.WindowPunctuationOutputMode;
import com.ibm.streams.operator.model.OutputPorts;
import com.ibm.streams.operator.model.Parameter;
import com.ibm.streams.operator.model.PrimitiveOperator;
import com.ibm.streams.operator.types.ValueFactory;
import com.ibm.streams.operator.logging.TraceLevel;

import java.io.IOException;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.SQLException;
import java.sql.ResultSet;

/**
 * Class for an operator that receives a tuple and then optionally submits a tuple. 
 * This pattern supports one or more input streams and one or more output streams. 
 * <P>
 * The following event methods from the Operator interface can be called:
 * </p>
 * <ul>
 * <li><code>initialize()</code> to perform operator initialization</li>
 * <li>allPortsReady() notification indicates the operator's ports are ready to process and submit tuples</li> 
 * <li>process() handles a tuple arriving on an input port 
 * <li>processPuncuation() handles a punctuation mark arriving on an input port 
 * <li>shutdown() to shutdown the operator. A shutdown request may occur at any time, 
 * such as a request to stop a PE or cancel a job. 
 * Thus the shutdown() may occur while the operator is processing tuples, punctuation marks, 
 * or even during port ready notification.</li>
 * </ul>
 * <p>With the exception of operator initialization, all the other events may occur concurrently with each other, 
 * which lead to these methods being called concurrently by different threads.</p> 
 */
@PrimitiveOperator(name="CrossDCSnapshotJdbcReader", namespace="com.ibm.streamsx.crossdc.failover",
description="Java Operator CrossDCSnapshotJdbcReader")
@InputPorts({@InputPortSet(description="Port that ingests tuples", cardinality=1, optional=false, windowingMode=WindowMode.NonWindowed, windowPunctuationInputMode=WindowPunctuationInputMode.Oblivious), @InputPortSet(description="Optional input ports", optional=true, windowingMode=WindowMode.NonWindowed, windowPunctuationInputMode=WindowPunctuationInputMode.Oblivious)})
@OutputPorts({@OutputPortSet(description="Port that produces tuples", cardinality=1, optional=false, windowPunctuationOutputMode=WindowPunctuationOutputMode.Generating), @OutputPortSet(description="Optional output ports", optional=true, windowPunctuationOutputMode=WindowPunctuationOutputMode.Generating)})
public class CrossDCSnapshotJdbcReader extends AbstractOperator {
	private static final String PACKAGE_NAME = "com.ibm.streamsx.crossdc.failover";
	// logger for trace/debug information
	protected static Logger TRACE = Logger.getLogger(PACKAGE_NAME);
	
	private String jdbcDriverLib = "";
	private String jdbcClassName = "";
	private String jdbcUrl = "";
	private String jdbcUser = "";
	private String jdbcPassword = "";
	private String tableName = "";
	private String primaryKeyColumnName = "id";
	private Connection dbConnection = null;
	private PreparedStatement queryStatement = null;
	private PreparedStatement queryAllStatement = null;
	private Thread dbConnectionStatusCheckerThread = null;
	
    /**
     * Initialize this operator. Called once before any tuples are processed.
     * @param context OperatorContext for this operator.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
	@Override
	public synchronized void initialize(OperatorContext context)
			throws Exception {
    	// Must call super.initialize(context) to correctly setup an operator.
		super.initialize(context);
        TRACE.log(TraceLevel.TRACE, 
            	"Operator " + context.getName() + 
            	" initializing in PE: " + context.getPE().getPEId() + 
            	" in Job: " + context.getPE().getJobId());
		
        // TODO:
        // If needed, insert code to establish connections or resources to communicate an external system or data store.
        // The configuration information for this may come from parameters supplied to the operator invocation, 
        // or external configuration files or a combination of the two.
        //
        // This operator will do its database tasks only if the user has 
        // configured certain important operator parameters.
        if (jdbcDriverLib.equalsIgnoreCase("") || 
        	jdbcClassName.equalsIgnoreCase("") || 
        	jdbcUrl.equalsIgnoreCase("") || 
        	tableName.equalsIgnoreCase("")) {
    		TRACE.log(TraceLevel.ERROR, "Operator " + context.getName() + 
    			" Not all the required operator parameters are specified." +
    			" So, this operator will not perform the intended DB operation.");
        	return;
        }
        
    	// Set up JDBC driver class path
		TRACE.log(TraceLevel.DEBUG, "Operator " + context.getName() + " setting up class path...");
			
		if(!setupClassPath(context)) {
				TRACE.log(TraceLevel.ERROR, "Operator " + context.getName() + " setting up class path failed.");
			throw new IOException();
		}
		
        //Load class into memory
        Class.forName(jdbcClassName);
        DriverManager.setLoginTimeout(5);
        
        // Open a connection to the database.
        try {
        	dbConnection = DriverManager.getConnection(jdbcUrl, jdbcUser, jdbcPassword); 
        	dbConnection.setAutoCommit(true);
        	String sql = "SELECT * from " + tableName + 
            	" where " + primaryKeyColumnName + "=?";
            queryStatement = dbConnection.prepareStatement(sql);
            sql = "SELECT * from " + tableName;
            queryAllStatement = dbConnection.prepareStatement(sql);
        } catch (SQLException ex) {
            // ex.printStackTrace();
        	dbConnection = null;
            throw(ex);
        }
        
        startDatabaseConnectionStatusChecker(context);
	}

    /**
     * Notification that initialization is complete and all input and output ports 
     * are connected and ready to receive and submit tuples.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    @Override
    public synchronized void allPortsReady() throws Exception {
    	// This method is commonly used by source operators. 
    	// Operators that process incoming tuples generally do not need this notification. 
        OperatorContext context = getOperatorContext();
        TRACE.log(TraceLevel.TRACE, 
            	"Operator " + context.getName() + 
            	" all ports are ready in PE: " + 
            	context.getPE().getPEId() + " in Job: " + 
            	context.getPE().getJobId());
    }

    /**
     * Process an incoming tuple that arrived on the specified port.
     * <P>
     * Copy the incoming tuple to a new output tuple and submit to the output port. 
     * </P>
     * @param inputStream Port the tuple is arriving on.
     * @param tuple Object representing the incoming tuple.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    @Override
    public final void process(StreamingInput<Tuple> inputStream, Tuple tuple)
            throws Exception {

    	// Create a new tuple for output port 0
        StreamingOutput<OutputTuple> outStream = getOutput(0);
        OutputTuple outTuple = outStream.newTuple();

        // Copy across all matching attributes.
        outTuple.assign(tuple);

        // TODO: Insert code to perform transformation on output tuple as needed:
        // outTuple.setString("AttributeName", "AttributeValue");
        //
        if (dbConnection == null) {
        	// DB connection is not valid at this time. 
        	// Requested DB action can't be performed.
        	return;
        }
        
        try {
	        // If the first attribute of the incoming tuple is set to * i.e. an asterisk,
	        // then we will do a select all statement.
	        ResultSet resultSet = null;
	        
	        if (tuple.getString(0).equalsIgnoreCase("*") == true) {
	        	// System.out.println("Executing query for all items.");
	        	resultSet = queryAllStatement.executeQuery();
	        } else {
	        	// System.out.println("Executing query for one item.");
	        	queryStatement.setString(1,  tuple.getString(0));
	        	resultSet = queryStatement.executeQuery();
	        }
	        
	        while (resultSet.next()) {
	        	// id column
	        	outTuple.setString(0, resultSet.getString(1));
	        	// replicationTime column
	        	outTuple.setString(1, resultSet.getString(2));
	        	outTuple.setBlob(2, ValueFactory.newBlob(resultSet.getBytes(3)));
	            // Submit new tuple to output port 0
	            outStream.submit(outTuple);
	        }
	        
	        // If we responded for a "read all rows" query, let us also inject a 
	        // punctuation after sending all the row results.
	        if (tuple.getString(0).equalsIgnoreCase("*") == true) {
	        	outStream.punctuate(Punctuation.WINDOW_MARKER);
	        }
	    } catch (SQLException se) {
	    	// Either the statement object or the DB connection is not valid anymore.
	    	// In that case, a watchdog thread below will attempt to reconnect.
	        TRACE.log(TraceLevel.ERROR, 
	            "Operator " + getOperatorContext().getName() + "-->" +
	            "SQL operation threw an exception with this message:" +
	            se.getMessage());
	    }
    }
    
    /**
     * Process an incoming punctuation that arrived on the specified port.
     * @param stream Port the punctuation is arriving on.
     * @param mark The punctuation mark
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    @Override
    public void processPunctuation(StreamingInput<Tuple> stream,
    		Punctuation mark) throws Exception {
    	// For window markers, punctuate all output ports 
    	super.processPunctuation(stream, mark);
    }

    /**
     * Shutdown this operator.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    public synchronized void shutdown() throws Exception {
        OperatorContext context = getOperatorContext();

        TRACE.log(TraceLevel.TRACE, "Operator " + 
        		context.getName() + " shutting down in PE: " + 
        	context.getPE().getPEId() + " in Job: " + 
        	context.getPE().getJobId());
        
        // TODO: If needed, close connections or release resources related to any external system or data store.
        if (dbConnection != null) {
        	queryStatement.close();
        	queryAllStatement.close();
        	dbConnection.close();
        }

		// Stop the DB connection status checker thread.
		if (dbConnectionStatusCheckerThread != null) {
			if (dbConnectionStatusCheckerThread.isAlive()) {
				dbConnectionStatusCheckerThread.interrupt();
			}
		}
        
        // Must call super.shutdown()
        super.shutdown();
    }
    
    /**
	 * startDatabaseConnectionStatusChecker starts a thread to check the JDBC connection.
	 * In case of any connection problem it tries to create a new connection.
	 * @param context
	 */
    public void startDatabaseConnectionStatusChecker(OperatorContext context) {
    	dbConnectionStatusCheckerThread = context.getThreadFactory().newThread(new Runnable() {
			
		@Override
		public void run() {
			int dbReconnectionAttemptCnt = 0;
			
			// Stay in this while loop for a long time.
			while(Thread.currentThread().isInterrupted() == false) {
				// Do the DB connection status check every 5 seconds.
				try {
					Thread.sleep(5000);
				} catch(InterruptedException iex) {
					Thread.currentThread().interrupt();
				}
				
				try {
					// Check if the DB connection is still valid.
					if (dbConnection == null || dbConnection.isValid(2) == false) {
						// DB connection is invalid. Close and try to reopen the connection.
						if (dbConnection != null) {
				            TRACE.log(TraceLevel.ERROR, 
			            		"Operator " + getOperatorContext().getName() + "-->" +
	            				"DB connection is not valid. Going to clean up and then attempt to reconnect.");
				            
				            try {
				            	queryStatement.close();
				            } catch (Exception ex) {
				            }
				            
				            try {
				            	queryAllStatement.close();
				            } catch (Exception ex) {
				            }
				            
				            try {
				            	dbConnection.close();
				            } catch (Exception ex) {
				            }
				            
				        	dbConnection = null;
						}
						
						dbReconnectionAttemptCnt++;
			        	dbConnection = DriverManager.getConnection(jdbcUrl, jdbcUser, jdbcPassword); 
			        	dbConnection.setAutoCommit(true);
			        	String sql = "SELECT * from " + tableName + 
			                " where " + primaryKeyColumnName + "=?";
			        	queryStatement = dbConnection.prepareStatement(sql);
			        	sql = "SELECT * from " + tableName;
			        	queryAllStatement = dbConnection.prepareStatement(sql);
			        	TRACE.log(TraceLevel.ERROR, 
			            	"Operator " + getOperatorContext().getName() + "-->" +
	            			"Successfully reconnected after " + dbReconnectionAttemptCnt + " attempt(s).");
			            dbReconnectionAttemptCnt = 0;
					}
				} catch (Exception ex) {
					// We can't do much with this exception. 
					// We will keep trying periodically to reconnect.
				}
			} // End of the while loop.
		} // End of run.
		});
    	
    	// Start this thread.
    	dbConnectionStatusCheckerThread.start();
    }
    
    // Set up JDBC driver class path
 	private boolean setupClassPath(OperatorContext context) throws MalformedURLException{	
 		String libDir = jdbcDriverLib;
 				
 		if (jdbcDriverLib.lastIndexOf(File.separator) > 0) {
 			libDir = jdbcDriverLib.substring(0, jdbcDriverLib.lastIndexOf(File.separator));
 		}
 		
 		TRACE.log(TraceLevel.INFO, "Operator " + context.getName() + "setupClassPath " + jdbcDriverLib + " " + libDir);
 		 	
 		String jarDir = libDir;
 		File f = new File(libDir);
 		
 		if (!f.isAbsolute()) {
 			File appDir = getOperatorContext().getPE().getApplicationDirectory();
 			TRACE.log(TraceLevel.INFO, "Operator " + context.getName() + " extending relative path '" + libDir + "' by the '" + appDir + "' directory");
 			jarDir = appDir +  File.separator + libDir;
 		}
 		
 		File jarDirectory = new File(jarDir);
 		
 		// Check if directory exists.
 		if(!jarDirectory.exists())
 		{
 			TRACE.log(TraceLevel.ERROR, "Operator " + context.getName() + " ERROR: jdbcDriverLib " + jarDir + " doesn't exist or it is empty.");
 			return false;
 		}
 		
 		// Check if directory contains files
 		File[] files = new File(jarDir).listFiles();
 		
 		if (files.length == 0){
 			TRACE.log(TraceLevel.ERROR, "Operator " + context.getName() + " ERROR: jdbcDriverLib directory " + jarDir + " is empty.");
 			return false;
 		}
 		
 		// If this pathname does not denote a directory, then listFiles() returns null. 
 		// Search in the "opt" directory and add all jar files to the class path. 
 		boolean jarFileFound = false;
 		
 		for (File file : files) {
 			if (file.isFile()) {
				String jarFile = jarDir + File.separator + file.getName();
				// check if the file is a JAR file
				if (jarFile.endsWith(".jar")){
					jarFileFound = true;
					TRACE.log(TraceLevel.INFO, "Operator " + context.getName() + "setupClassPath " + jarFile);
					context.addClassLibraries(new String[] {jarFile});
				}
 			}
 		}
 		
 		if (!jarFileFound){
 			TRACE.log(TraceLevel.ERROR, "Operator " + context.getName() + " ERROR: No JAR file found in jdbcDriverLib directory: " + jarDir);
 			return false;
 		}
 		else {
 			TRACE.log(TraceLevel.DEBUG, "Operator " + context.getName() + " JDBC Driver Lib: " + jdbcDriverLib);
 		}
 		
 		return true;
 	}

 	
	@Parameter(name="jdbcDriverLib", description="Specify your JDBC driver name", optional=false)
	public void setJdbcDriverLib(String value) {
		jdbcDriverLib = value;
	}
	
	@Parameter(name="jdbcClassName", description="Specify your JDBC class name", optional=false)
	public void setJdbcClassName(String value) {
		jdbcClassName = value;
	}

	@Parameter(name="jdbcUrl", description="Specify your JDBC URL name", optional=false)
	public void setJdbcUrl(String value) {
		jdbcUrl = value;
	}
	
	@Parameter(name="jdbcUser", description="Specify your database user name", optional=false)
	public void setJdbcUser(String value) {
		jdbcUser = value;
	}

	@Parameter(name="jdbcPassword", description="Specify your database password", optional=false)
	public void setJdbcPassword(String value) {
		jdbcPassword = value;
	}

	@Parameter(name="tableName", description="Specify your database table name", optional=false)
	public void setTableName(String value) {
		tableName = value;
	}
	
	@Parameter(name="primaryKeyColumnName", description="Specify your primary key column name", 
		optional=true)
	public void setPrimaryKeyColumnName(String value) {
		primaryKeyColumnName = value;
	} 
}
